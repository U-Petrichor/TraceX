# P1｜主机日志采集模块定位（总览页）

## 🎯 这一页你要回答的问题
“你这个模块，在整个系统里是干嘛的？”

## PPT 标题
**Host Collector：高保真主机行为日志采集模块**

## 核心功能定位
*   **面向 Linux 主机** 的内核级行为采集
*   **全维度覆盖**：进程 (Process) / 文件 (File) / 网络 (Network) / 用户 (User) / 内存 (Memory)
*   **核心价值**：为攻击链分析提供 **可信原始证据 (Source of Truth)**

## 系统分层架构描述
*   **上层 (Attack Analysis)**：负责攻击链构建与 APT 分析，接收标准化的 UnifiedEvent。
*   **中间层 (Host Collector)**：**本模块核心**。作为内核与分析层之间的桥梁，负责采集 syscall 和 proc 数据，进行清洗与标准化。
*   **底层 (Linux Kernel)**：数据源头，提供原始的系统调用 (syscall) 和进程状态信息。

## 演讲提示词
👉 **你这页只讲一句话：**
“我负责的是最底层、最原始、最难规避的数据来源。我们不依赖应用层日志，而是直接监听 Linux 内核的系统调用，让攻击行为无处遁形。”

---

# P2｜内核级日志采集架构（auditd）

## 🎯 这一页你要回答的问题
“你怎么保证你看得全？”

## PPT 标题
**内核级审计：全覆盖的主机行为采集**

## 核心采集规则 (`auditd_config.py`)
*   **全覆盖监控**：基于 Linux Auditd 框架，实现系统调用级监控。
*   **关键行为锚点**：
    *   `execve`: 捕获所有进程启动与命令行参数。
    *   `connect`: 捕获所有网络外连行为。
    *   `/etc/passwd`: 捕获敏感文件的读写与属性修改。
*   **持久化保障**：集成 Systemd 托管与 Cron 保活机制。

## 数据流转与处理机制
1.  **触发 (Trigger)**：用户操作或恶意软件触发系统调用 (Syscall)。
2.  **捕获 (Trap)**：Linux Kernel 捕获调用并传递给 auditd 守护进程。
3.  **日志化 (Logging)**：auditd 生成原始的多行碎片日志 (SYSCALL / PATH / EXECVE)。
4.  **采集与重组 (Aggregation)**：Host Collector Agent 读取碎片日志，将其重组为完整的行为事件。
5.  **标准化 (Output)**：输出符合 TraceX Schema 的 UnifiedEvent。

## 演讲提示词
“我们不靠应用日志（比如 Nginx 日志），而是直接从内核抓行为。
比如攻击者修改了 `/etc/passwd`，无论他用 `vi` 还是 `echo`，底层都会触发 `open` 和 `write` 系统调用，这正是我们监控的锚点。”

---

# P3｜内存行为日志采集（你的王牌页）

🔥 **这是你最强的一页，建议讲 1 分钟**

## PPT 标题
**无文件攻击感知：内存行为日志采集**

## 核心检测能力 (`BehaviorAnalyzer`)
*   **无文件执行检测**：识别 `memfd_create` 等内存文件执行行为。
*   **内存篡改检测**：监控 `mprotect` 产生的 RWX (可读可写可执行) 异常内存段。
*   **进程注入检测**：发现 `ptrace` 等调试与注入行为。
*   **启发式序列分析**：基于 Syscall 序列 (如 Write -> Mprotect -> Jump) 判定攻击意图。

## 攻击与检测流程描述
1.  **攻击阶段**：
    *   恶意软件调用 `memfd_create` 创建内存文件。
    *   写入 Payload 并调用 `mprotect` 将内存段设为 RWX。
    *   跳转执行恶意代码。
2.  **检测阶段**：
    *   Collector 捕获异常 Syscall 序列。
    *   触发 `mem_scanner` 扫描进程内存空间 (maps / vm_flags)。
    *   提取内存特征并告警。

## 演讲提示词
“很多高级攻击（如 Cobalt Strike）根本不落盘，传统杀毒软件很难发现。
我们实现了**基于行为序列的内存检测**：一旦发现 `memfd_create` 后紧接着 `execve`，或者进程申请了 `RWX`（可读可写可执行）内存段，我们的 `mem_scanner` 就会立即介入，直接从内存中提取证据。”

---

# P4｜日志解析 & 统一建模（ETL）

## 🎯 这一页你要回答的问题
“你采到了，那数据能不能用？”

## PPT 标题
**日志解析与统一建模 (UnifiedEvent)**

## 关键处理逻辑
*   **碎片日志重组**：
    *   Auditd 日志通常将一个行为拆分为多行 (SYSCALL, EXECVE, CWD, PATH)。
    *   Parser 使用状态机逻辑，基于 audit_id 将分散的日志行聚合成单一原子事件。
*   **会话上下文增强**：
    *   维护 `session_id` 到 `source.ip` 的映射缓存。
    *   自动将后续的进程/文件操作关联到初始登录 IP，解决内网溯源难题。
*   **五维实体建模**：
    *   将原始数据映射为标准化的 Process, File, Network, User, Memory 实体对象。

## 演讲提示词
“原始的 auditd 日志非常晦涩，而且是多行碎片的。
我们的 Parser 就像一个‘翻译官’，把这些碎片拼凑起来，并补充上下文（比如这个进程是谁通过哪个 IP 登录后启动的），最终输出一份标准化的、人类可读的 JSON 事件。”

---

# P5｜工程可靠性设计（兜底页）

## 🎯 这一页你要防的问题
“日志多了会不会丢？会不会把主机拖死？”

## PPT 标题
**工程可靠性：断点续传与资源保护**

## 核心可靠性机制 (`auditd_agent.py`)
*   **断点续传 (State Management)**：
    *   通过 `agent_state.json` 实时记录文件 inode 和读取 offset。
    *   确保 Agent 重启或异常退出后，数据零丢失，采集不重不漏。
*   **日志轮转适配 (Log Rotation)**：
    *   自动监测 `audit.log` 的 inode 变化。
    *   平滑处理日志切割，无缝切换文件句柄。
*   **资源过载保护 (Resource Protection)**：
    *   **噪点过滤**：自动过滤高频低价值进程 (如 sleep, awk, date)。
    *   **熔断机制**：设置 CPU 使用率阈值，高负载下自动降级或暂停，防止影响业务。

## 演讲提示词
“为了保证在生产环境的稳定性，我们做了大量的工程化工作。
比如**断点续传**机制，即使 Agent 意外挂掉，重启后也能从上次断开的地方继续采集，保证数据**一条不丢**。同时，我们内置了**熔断机制**，防止在高负载下占用过多 CPU。”
