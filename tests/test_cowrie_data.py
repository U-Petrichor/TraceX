import sys
import json
from datetime import datetime, timedelta

# 1. å¼•å…¥å…¬å…±æ¨¡å—
sys.path.append('/root/TraceX')
try:
    from collector.common.es_client import ESClient
    from collector.common.schema import UnifiedEvent
except ImportError:
    print("é”™è¯¯: æ— æ³•åŠ è½½å…¬å…±æ¨¡å—ï¼Œè¯·æ£€æŸ¥ç›®å½•ç»“æ„æ˜¯å¦ä¸º /root/TraceX/collector/common/")
    sys.exit(1)

class DataValidator:
    """æ•°æ®è´¨é‡è‡ªæ£€å·¥å…·"""

    def __init__(self):
        self.es = ESClient()
        self.stats = {
            "total": 0,
            "valid": 0,
            "invalid": 0,
            "missing_fields": {},
            "type_errors": 0
        }

    def check_quality(self, hours=1):
        """æ£€æŸ¥è¿‡å» X å°æ—¶å†…çš„æ•°æ®è´¨é‡"""
        now = datetime.utcnow()
        start_time = (now - timedelta(hours=hours)).isoformat() + "Z"
        end_time = now.isoformat() + "Z"

        print(f"[*] å¼€å§‹è‡ªæ£€æ—¶é—´æ®µ: {start_time} è‡³ {end_time}")
        
        # è°ƒç”¨å…¬å…±æ¥å£æŸ¥è¯¢æ•°æ®
        events = self.es.query_events(start_time, end_time, size=500)
        self.stats["total"] = len(events)

        if not events:
            print("[!] è­¦å‘Š: æœªåœ¨ ES ä¸­å‘ç°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥ flow_parser.py æ˜¯å¦æ­£åœ¨è¿è¡Œã€‚")
            return

        for doc in events:
            self._validate_document(doc)

        self._print_report()

    def _validate_document(self, doc):
        """æ ¹æ® UNIFIED_EVENT_SCHEMA æ ¡éªŒæ–‡æ¡£å­—æ®µ"""
        is_valid = True
        errors = []

        # 1. æ ¸å¿ƒå¿…å¡«å­—æ®µæ ¡éªŒ
        mandatory_fields = ["@timestamp", "event", "source", "host"]
        for field in mandatory_fields:
            if field not in doc:
                is_valid = False
                self.stats["missing_fields"][field] = self.stats["missing_fields"].get(field, 0) + 1
                errors.append(f"ç¼ºå¤±å¿…å¡«ä¸»å­—æ®µ: {field}")

        # 2. ä¸¥é‡ç¨‹åº¦é€»è¾‘æ ¡éªŒ (1-10)
        severity = doc.get("event", {}).get("severity", 0)
        if not (1 <= severity <= 10):
            is_valid = False
            self.stats["type_errors"] += 1
            errors.append(f"Severity è¶Šç•Œ: {severity}")

        # 3. æ•°æ®æ¥æºæ ¡éªŒ
        if not doc.get("event", {}).get("dataset"):
            is_valid = False
            errors.append("ç¼ºå¤±æ•°æ®æ¥æºæ ‡è¯† (dataset)")

        # 4. å…³é”®ä¸šåŠ¡å­—æ®µæ ¡éªŒ (é’ˆå¯¹èœœç½è¿æ¥)
        if doc.get("event", {}).get("action") == "cowrie.session.connect":
            if not doc.get("source", {}).get("ip"):
                is_valid = False
                errors.append("è¿æ¥äº‹ä»¶ç¼ºå¤±æº IP")

        if is_valid:
            self.stats["valid"] += 1
        else:
            self.stats["invalid"] += 1
            # print(f"[X] æ–‡æ¡£ ID {doc.get('event', {}).get('id')} æ ¡éªŒå¤±è´¥: {errors}")

    def _print_report(self):
        """æ‰“å°è´¨é‡åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*40)
        print("ğŸ“Š æ•°æ®è´¨é‡è‡ªæ£€æŠ¥å‘Š")
        print("="*40)
        print(f"æ€»æ£€æŸ¥æ¡æ•°: {self.stats['total']}")
        print(f"âœ… åˆæ ¼æ¡æ•°: {self.stats['valid']}")
        print(f"âŒ ä¸åˆæ ¼æ¡æ•°: {self.stats['invalid']}")
        
        if self.stats["invalid"] > 0:
            print("\nä¸»è¦é—®é¢˜ç»Ÿè®¡:")
            for field, count in self.stats["missing_fields"].items():
                print(f"- ç¼ºå¤±å­—æ®µ '{field}': {count} æ¬¡")
            print(f"- å­—æ®µç±»å‹/é€»è¾‘é”™è¯¯: {self.stats['type_errors']} æ¬¡")
        
        score = (self.stats["valid"] / self.stats["total"]) * 100 if self.stats["total"] > 0 else 0
        print(f"\nå¥åº·åˆ†: {score:.1f}/100")
        if score < 90:
            print("[å»ºè®®] æ•°æ®è´¨é‡è¾ƒä½ï¼Œè¯·æ£€æŸ¥ flow_parser.py çš„æ˜ å°„é€»è¾‘ã€‚")
        else:
            print("[ä¼˜ç§€] æ•°æ®æ ¼å¼å®Œç¾ï¼Œç»„å‘˜ 3 å’Œ 4 å¯ä»¥æ”¾å¿ƒä½¿ç”¨ã€‚")
        print("="*40)

if __name__ == "__main__":
    validator = DataValidator()
    # æ£€æŸ¥è¿‡å» 24 å°æ—¶çš„æ•°æ®
    validator.check_quality(hours=24)
