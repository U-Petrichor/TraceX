# 组员1任务详解：主机日志采集与防御

## 任务概览
负责 Linux 主机日志的采集、解析与标准化，以及基于内存行为的高级威胁检测。重点关注系统审计日志（Auditd）、系统日志（Syslog）及内存无文件攻击防御。

## 1. Linux Host Collector (纯 Python 采集引擎)

### 1.1 采集架构
系统采用轻量级的纯 Python 架构，直接从内核审计子系统获取数据，无需依赖 Filebeat 等外部组件。
*   **链路**: Linux Auditd -> **auditd_agent.py (Direct)** -> Elasticsearch
*   **优势**: 零外部依赖，单进程部署，资源占用极低。

### 1.2 高可用与数据可靠性 (Reliability)
为了确保生产环境的数据完整性，采集引擎内置了以下核心机制：

#### 1.2.1 断点续传 (Checkpointing)
*   **机制**: 维护状态文件 `agent_state.json`，持久化记录当前文件的 `inode` 和读取偏移量 `offset`。
*   **效果**: 服务重启或异常崩溃后，可毫秒级恢复至上次读取位置，杜绝数据重复或丢失。

#### 1.2.2 日志轮转处理 (Log Rotation Handling)
*   **机制**: 实时监控 `/var/log/audit/audit.log` 的 `inode` 变化。
*   **效果**: 当系统自动切割日志时，Agent 能够自动感知并无缝切换至新文件头部继续采集。

#### 1.2.3 智能解析与降级 (Smart Parsing with Fallback)
*   **机制**: 采用 **Try-Catch-Fallback** 策略处理日志流。
    *   **Normal**: 解析为符合 Schema 标准的结构化数据。
    *   **Fallback**: 遇到非标或截断日志时，自动标记为 `event.category="raw_log"` 并保留原始文本入库。
*   **效果**: 确保所有审计痕迹100%留存。

### 1.3 启动与验证

#### 1.3.1 环境准备 (Prerequisites)
运行 Host Collector 之前，请确保已安装必要的 Python 依赖库：

```bash
# 在项目根目录下执行
pip3 install -r requirements.txt
# 或者手动安装
pip3 install psutil elasticsearch pyyaml requests
```

#### 1.3.2 启动服务
采集器已集成在项目根目录的启动脚本中，或单独运行：

```bash
# 单独运行 Host Collector
export PYTHONPATH=$PYTHONPATH:.
python3 collector/host_collector/auditd_agent.py
```

## 2. Windows 事件日志解析支持

为了支持跨平台日志采集，系统在 `collector/host_collector/log_parser.py` 中集成了 Windows Event Log (JSON 格式) 解析引擎。

### 2.1 支持的事件类型
目前支持以下核心安全事件的标准化映射：

| EventID | 事件类型 | 映射到 UnifiedEvent (Schema) | 关键字段提取 |
| :--- | :--- | :--- | :--- |
| **4624** | 登录成功 | `event.category="authentication"`<br>`event.action="login"` | `user.name` (TargetUserName)<br>`source.ip` (IpAddress) |
| **4688** | 进程创建 | `event.category="process"`<br>`event.action="process_created"` | `process.executable` (NewProcessName)<br>`process.command_line` (CommandLine)<br>`process.pid` (ProcessId) |
| **4663** | 对象访问 | `event.category="file"`<br>`event.action="access"` | `file.path` (ObjectName)<br>`file.name` (文件名) |

### 2.2 实现逻辑
*   **统一入口**: `HostLogParser.parse(raw_data, log_type="windows")`
*   **兼容性**: 通过 `log_type` 参数区分 Linux/Windows 日志流。
*   **数据清洗**: 自动规范化 Windows XML/JSON 中的十六进制 PID 和非标时间戳。

### 2.3 测试与演示 (Testing & Demo)

#### 2.3.1 单元测试 (Unit Test)
*   **目标**: 验证 Windows 日志解析逻辑的 Schema 合规性。
*   **命令**: `python tests/test_host_collector_windows_parser_compliance.py`

#### 2.3.2 集成演示 (Integration Demo)
*   **目标**: 模拟从日志生成到 Kibana 可视化的全过程。
*   **命令**: `python3 tests/test_host_collector_windows_es_integration.py`
*   **结果**: 控制台输出 `Ingested Event... Result: created` 即表示成功。

## 3. 核心功能实现 (Function Implementation)

### 3.1 Linux 多行日志聚合

#### 业务场景
Linux Auditd 日志采用“流式多行记录”格式，单次操作（如 `cat /etc/shadow`）会分散在 SYSCALL（进程）、CWD（目录）、PATH（文件）等多条记录中。

#### 技术实现 (Implementation)
系统引入了 **有状态解析 (Stateful Parsing)** 机制：
*   **聚合逻辑**: 利用 `_audit_buffer` 缓存同一 `audit_id` 的上下文，采用 **“新 ID 触发旧事件刷新 (Flush-on-New-ID)”** 策略。
*   **字段还原**:
    *   **EXECVE**: 自动拼接 `a0`, `a1`... 参数为完整命令行。
    *   **PATH**: 智能提取 `nametype=NORMAL` 的目标文件路径。

#### 实测效果
在执行 `sudo cat /etc/shadow` 的测试中，系统能生成单条包含完整上下文的事件：
*   **Event**: `process.name="cat"` AND `file.path="/etc/shadow"`
*   **Value**: 直接还原攻击链路，无需人工二次关联。

### 3.2 数据标准化与元数据增强 (Data Enrichment)
系统在解析阶段注入了丰富的上下文信息，以提升分析价值：
*   **时间对齐**: 统一使用 `process.start_time` 记录进程启动时间。
*   **自动打标 (Auto-Tagging)**: 基于行为特征自动填充 `metadata.atlas_label`。
    *   例如：操作 `/tmp/` 目录标记为 `TEMP_FILE`；执行 `.sh` 脚本标记为 `SCRIPT_EXEC`。
*   **进程树补全**: 内置 PPID 提取逻辑，完整还原 `parent -> child` 调用链。

## 4. 内存行为防御体系 (TraceX MemDefense)

### 4.1 功能能力 (Capabilities)
本系统包含一套独立的**内存防御子系统**，用于检测无文件攻击 (Fileless Attack) 和高级内存注入行为：
1.  **Shellcode 注入**: 识别内存中异常的“写+执行” (RWX) 区域。
2.  **Reflective ELF Loading (反射加载)**: 检测不落地直接在内存中执行的 ELF 二进制文件。
3.  **Process Hollowing**: 发现匿名内存映射中的非法可执行代码。

### 4.2 技术架构 (Architecture)
采用**“C++ 核心引擎 + Python 行为调度”**的双层混合架构：

#### 4.2.1 C++ 核心引擎 (`mem_scanner`)
*   **定位**: 高性能底层扫描单元。
*   **核心技术**:
    *   **RWX Hunting**: 快速定位 `vm_flags` 包含 `rd`+`wr`+`ex` 的内存页。
    *   **ELF Fingerprinting**: 使用 `process_vm_readv` 远程读取内存头，匹配 `\x7fELF` 魔数。
    *   **风险分级 (Risk Scoring)**:
        *   **CRITICAL**: 发现 ELF 头 或 堆栈可执行。
        *   **HIGH**: 匿名 RWX 内存。
        *   **MEDIUM**: 有文件映射的 RWX。
*   **安全机制**: 强制 Root 权限运行，内置白名单机制（`--whitelist`）以兼容 JIT 进程。

#### 4.2.2 Python 行为调度器 (`BehaviorAnalyzer`)
*   **定位**: 业务决策与调度中心。
*   **双模触发机制**:
    1.  **攻击序列触发 (Event-Driven)**: 实时监控系统调用，匹配 `ptrace` + `write` (注入) 或 `memfd_create` + `execve` (无文件执行) 等攻击序列，毫秒级触发扫描。
    2.  **动态负载巡检 (Smart Periodic)**: 智能感知系统负载，在空闲时段（CPU < 80%）执行全量健康检查。

### 4.3 使用与部署 (Deployment)

#### 4.3.1 部署方式
由于生产服务器通常不具备编译环境 (g++)，我们提供两种部署模式。请根据实际情况选择：

**模式 A：预编译部署（推荐，标准生产环境）**
*   **适用场景**: 生产服务器 (Target Server) 禁止安装编译器，或为了统一部署版本。
*   **操作流程**:
    1.  **构建 (Build)**: 在与生产环境架构一致（如 Linux x86_64）的 **开发机/构建机** 上运行：
        ```bash
        cd collector/host_collector/mem_scanner
        make
        # 成功后会在当前目录生成二进制文件: mem_scanner
        ```
    2.  **传输 (Transfer)**: 将生成的 `mem_scanner` 文件上传至 **生产服务器** 的指定目录。
        ```bash
        # 示例: 上传至生产服务器
        scp mem_scanner root@prod-server:/opt/tracex/bin/
        ```
    3.  **赋权 (Permission)**: 在 **生产服务器** 上赋予执行权限。
        ```bash
        chmod +x /opt/tracex/bin/mem_scanner
        ```

**模式 B：源码编译部署（测试环境/开发调试）**
*   **适用场景**: 开发调试，或服务器已具备完整的开发工具链。
*   **操作流程**:
    直接在 **目标服务器** 上运行根目录下的自动化构建脚本：
    ```bash
    ./build_mem_scanner.sh
    # 脚本会自动检查 g++ 环境 -> 编译 -> 安装至 /opt/tracex/bin
    ```

#### 4.3.2 运行与监控
部署完成后，Python Agent (`auditd_agent.py`) 会自动探测 `/opt/tracex/bin/mem_scanner` 是否存在。若存在，将自动接管调度，无需人工干预。
*   **Kibana 查询**: `event.category: "memory"`
*   **告警样例**:
    ```json
    {
      "event.action": "anomaly_detected",
      "event.reason": "Fileless Execution",
      "memory.anomalies": [
        {
          "type": "MEMFD_EXEC",
          "risk_level": "CRITICAL",
          "details": "Executable memfd with valid ELF header"
        }
      ]
    }
    ```
